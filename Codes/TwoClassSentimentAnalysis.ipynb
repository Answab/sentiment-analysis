{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0acfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef33909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           OriginalTweet\n",
      "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
      "1      advice Talk to your neighbours family to excha...\n",
      "2      Coronavirus Australia: Woolworths to give elde...\n",
      "3      My food stock is not the only one which is emp...\n",
      "4      Me, ready to go at supermarket during the #COV...\n",
      "...                                                  ...\n",
      "44950  Meanwhile In A Supermarket in Israel -- People...\n",
      "44951  Did you panic buy a lot of non-perishable item...\n",
      "44952  Asst Prof of Economics @cconces was on @NBCPhi...\n",
      "44953  Gov need to do somethings instead of biar je r...\n",
      "44954  I and @ForestandPaper members are committed to...\n",
      "\n",
      "[44955 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing dataset\n",
    "\n",
    "dataset = pd.read_csv(r\"C:\\Users\\ANSWEB\\Desktop\\Major Project\\Dataset\\TwitterDataset.csv\",\n",
    "    usecols=['OriginalTweet'], encoding='latin-1')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da50d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Lemmatized\n",
      "0                                                    NaN\n",
      "1      advice talk neighbour family exchange phone nu...\n",
      "2      coronavirus australia woolworth give elderly d...\n",
      "3      food stock one empty please dont panic enough ...\n",
      "4      ready go supermarket covid19 outbreak im paran...\n",
      "...                                                  ...\n",
      "44950  meanwhile supermarket israel people dance sing...\n",
      "44951  panic buy lot nonperishable item echo need foo...\n",
      "44952  asst prof economics talk recent research coron...\n",
      "44953  gov need somethings instead biar je rakyat ass...\n",
      "44954  member commit safety employee endusers monitor...\n",
      "\n",
      "[44955 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing lemmatized dataset\n",
    "\n",
    "Lemma = pd.read_csv(r\"C:\\Users\\ANSWEB\\Desktop\\Major Project\\Dataset\\LemmatizedData.csv\",\n",
    "    usecols=['Lemmatized'], encoding='latin-1')\n",
    "\n",
    "print(Lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcaffe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing vectorized dataset\n",
    "\n",
    "vectorizer=pd.read_csv(r\"C:\\Users\\ANSWEB\\Desktop\\Major Project\\Dataset\\TFIDFData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c576c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining textblob function \n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_polarity(text):\n",
    "    analysis = TextBlob(text)\n",
    "\n",
    "    # Get sentiment polarity\n",
    "    polarity = analysis.sentiment.polarity\n",
    "\n",
    "    # Label the tweet based on polarity\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5814af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing textblob analysis on lemmatized dataset\n",
    "\n",
    "dataset['TextBlobSentiment2C'] = Lemma['Lemmatized'].apply(lambda x : textblob_polarity(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5ec539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Negative\n",
       "1        Positive\n",
       "2        Negative\n",
       "3        Positive\n",
       "4        Negative\n",
       "           ...   \n",
       "44950    Positive\n",
       "44951    Positive\n",
       "44952    Negative\n",
       "44953    Negative\n",
       "44954    Negative\n",
       "Name: TextBlobSentiment2C, Length: 44955, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying textblob analyzed dataset \n",
    "\n",
    "dataset['TextBlobSentiment2C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1924e861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlobSentiment2C\n",
       "Negative    25282\n",
       "Positive    19673\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying number of sentiment values in dataset\n",
    "\n",
    "dataset.TextBlobSentiment2C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa416257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100k</th>\n",
       "      <th>100s</th>\n",
       "      <th>10am</th>\n",
       "      <th>19th</th>\n",
       "      <th>1m</th>\n",
       "      <th>1sanitizer</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2019ncov</th>\n",
       "      <th>21daylockdown</th>\n",
       "      <th>...</th>\n",
       "      <th>yoy</th>\n",
       "      <th>yr</th>\n",
       "      <th>yyc</th>\n",
       "      <th>y√£</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44950</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44951</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44952</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44953</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44955 rows √ó 4999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       100k  100s  10am  19th   1m  1sanitizer  1st   20  2019ncov  \\\n",
       "0       0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "1       0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "2       0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "3       0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "4       0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "...     ...   ...   ...   ...  ...         ...  ...  ...       ...   \n",
       "44950   0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "44951   0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "44952   0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "44953   0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "44954   0.0   0.0   0.0   0.0  0.0         0.0  0.0  0.0       0.0   \n",
       "\n",
       "       21daylockdown  ...  yoy   yr  yyc   y√£  zealand  zero  zimbabwe  \\\n",
       "0                0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "1                0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "2                0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "3                0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "4                0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "...              ...  ...  ...  ...  ...  ...      ...   ...       ...   \n",
       "44950            0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "44951            0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "44952            0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "44953            0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "44954            0.0  ...  0.0  0.0  0.0  0.0      0.0   0.0       0.0   \n",
       "\n",
       "       zombie  zone  zoom  \n",
       "0         0.0   0.0   0.0  \n",
       "1         0.0   0.0   0.0  \n",
       "2         0.0   0.0   0.0  \n",
       "3         0.0   0.0   0.0  \n",
       "4         0.0   0.0   0.0  \n",
       "...       ...   ...   ...  \n",
       "44950     0.0   0.0   0.0  \n",
       "44951     0.0   0.0   0.0  \n",
       "44952     0.0   0.0   0.0  \n",
       "44953     0.0   0.0   0.0  \n",
       "44954     0.0   0.0   0.0  \n",
       "\n",
       "[44955 rows x 4999 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying vectorized dataset\n",
    "\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5055e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train text split ratio of dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorizer, dataset.TextBlobSentiment2C, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b12d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing and training decision tree classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "decisiontree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ad2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.886108330552775\n"
     ]
    }
   ],
   "source": [
    "# train dataset accuracy\n",
    "\n",
    "predictions = decisiontree.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, predictions)\n",
    "#print(\"Train Accuracy:\", accuracy_train)\n",
    "\n",
    "# test dataset accuracy\n",
    "\n",
    "predictions = decisiontree.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, predictions)\n",
    "print(\"Test Accuracy:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312f074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the decision tree model\n",
    "\n",
    "#joblib.dump(decisiontree, 'decisiontree2c.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d2fa3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing and training randomforest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier(n_estimators=100)\n",
    "randomforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4633679a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8960071182293404\n"
     ]
    }
   ],
   "source": [
    "# train dataset accuracy\n",
    "\n",
    "predictions = randomforest.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, predictions)\n",
    "#print(\"Train Accuracy:\", accuracy_train)\n",
    "\n",
    "# test datatest accuracy\n",
    "\n",
    "predictions = randomforest.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, predictions)\n",
    "print(\"Test Accuracy:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d1f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the random forest model\n",
    "\n",
    "joblib.dump(randomforest, 'randomforest2c.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a392e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff1d1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with missing values\n",
    "\n",
    "Lemma.dropna(inplace=True)\n",
    "\n",
    "# converting labels to numeric values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['TextBlobSentiment2C'] = label_encoder.fit_transform(dataset['TextBlobSentiment2C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c50157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "44950    1\n",
       "44951    1\n",
       "44952    0\n",
       "44953    0\n",
       "44954    0\n",
       "Name: TextBlobSentiment2C, Length: 44955, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['TextBlobSentiment2C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46ec7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining rows to drop\n",
    "\n",
    "columns_to_drop=list(set(range(44955)) - set(Lemma['Lemmatized'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df1a8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns based on index values\n",
    "\n",
    "dataset.drop(index=columns_to_drop, axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2056e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train text split ratio of dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Lemma['Lemmatized'], dataset['TextBlobSentiment2C'], test_size=0.2, random_state=42)\n",
    "\n",
    "# tokenize the input data\n",
    "\n",
    "tokenizer2c = Tokenizer()\n",
    "tokenizer2c.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer2c.word_index) + 1\n",
    "X_train = tokenizer2c.texts_to_sequences(X_train)\n",
    "X_test = tokenizer2c.texts_to_sequences(X_test)\n",
    "\n",
    "# defining maximum sequence length and padding sequences to that fixed length\n",
    "    \n",
    "max_len = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b438256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the random forest model\n",
    "\n",
    "joblib.dump(tokenizer2c, 'TOKENIZER2C.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a58d38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "562/562 [==============================] - 90s 153ms/step - loss: 0.3569 - accuracy: 0.8382 - val_loss: 0.2137 - val_accuracy: 0.9192\n",
      "Epoch 2/10\n",
      "562/562 [==============================] - 84s 149ms/step - loss: 0.1099 - accuracy: 0.9598 - val_loss: 0.1638 - val_accuracy: 0.9409\n",
      "Epoch 3/10\n",
      "562/562 [==============================] - 85s 151ms/step - loss: 0.0512 - accuracy: 0.9823 - val_loss: 0.1601 - val_accuracy: 0.9492\n",
      "Epoch 4/10\n",
      "562/562 [==============================] - 82s 145ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.1893 - val_accuracy: 0.9507\n",
      "Epoch 5/10\n",
      "562/562 [==============================] - 82s 146ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.1982 - val_accuracy: 0.9474\n",
      "Epoch 6/10\n",
      "562/562 [==============================] - 83s 148ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.2502 - val_accuracy: 0.9480\n",
      "Epoch 7/10\n",
      "562/562 [==============================] - 86s 152ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.2168 - val_accuracy: 0.9519\n",
      "Epoch 8/10\n",
      "562/562 [==============================] - 87s 154ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.2056 - val_accuracy: 0.9551\n",
      "Epoch 9/10\n",
      "562/562 [==============================] - 85s 151ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.2447 - val_accuracy: 0.9491\n",
      "Epoch 10/10\n",
      "562/562 [==============================] - 85s 151ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.2497 - val_accuracy: 0.9489\n",
      "281/281 [==============================] - 5s 18ms/step - loss: 0.2497 - accuracy: 0.9489\n",
      "Accuracy: 0.9489148855209351\n"
     ]
    }
   ],
   "source": [
    "# creating a bilstm model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train_lstm = to_categorical(y_train)\n",
    "y_test_lstm = to_categorical(y_test)\n",
    "\n",
    "# training the model\n",
    "\n",
    "model.fit(X_train, y_train_lstm, epochs=10, batch_size=64, validation_data=(X_test, y_test_lstm))\n",
    "\n",
    "# testing the model\n",
    "\n",
    "_,accuracy = model.evaluate(X_test, y_test_lstm)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a83b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the bilstm model\n",
    "\n",
    "model.save('bilstm2c.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
